{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e0350ec-e9de-4382-b844-9ff098327fd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983aa42f-1fce-4e78-9ca3-63e14c92f661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2025-12-11T00:59:25.321192Z",
     "iopub.status.busy": "2025-12-11T00:59:25.320900Z",
     "iopub.status.idle": "2025-12-11T01:06:44.097210Z",
     "shell.execute_reply": "2025-12-11T01:06:44.096011Z",
     "shell.execute_reply.started": "2025-12-11T00:59:25.321146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q mlflow lightgbm\n",
    "!pip install synapseml\n",
    "\n",
    "\n",
    "# Databricks setup\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2c69a2-7200-4448-abb3-927b198f33cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7218d1-f86b-48b5-bb16-e52a13d993ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE cscie103_catalog.final_project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40b02ad-6fa5-4314-bdc0-cb7b1168a601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from silver_training LIMIT 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9919c0b3-9af8-4cb6-8962-fe2ea9760db3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use your catalog + schema\n",
    "spark.sql(\"USE cscie103_catalog.final_project\")\n",
    "\n",
    "# MLflow experiment in workspace\n",
    "mlflow.set_experiment(\"/Shared/store_sales_experiment\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load training data\n",
    "# ---------------------------------------------------------\n",
    "df = spark.table(\"silver_training\").toPandas()\n",
    "\n",
    "def make_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure datetime\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # Hash columns to exclude\n",
    "    hash_col = [\"hash_storeNbr_family_city_state_type_cluster\", \"transactions\", \"id\"]\n",
    "\n",
    "    # Convert categoricals same as training\n",
    "    cat_cols = [\"state\", \"store_nbr\", \"family\", \"city\", \"type\", \"cluster\", \"is_holiday\"]\n",
    "\n",
    "    # Convert to categorical codes (LightGBM-friendly)\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(\"category\").cat.codes\n",
    "\n",
    "    # Date to ordinal\n",
    "    df[\"date_ordinal\"] = df[\"date\"].map(pd.Timestamp.toordinal)\n",
    "\n",
    "    # Feature columns match training\n",
    "    feature_cols = [\n",
    "        c for c in df.columns\n",
    "        if c not in [\"sales\", \"date\"] + hash_col\n",
    "    ]\n",
    "\n",
    "    return df, feature_cols\n",
    "\n",
    "df, feature_cols = make_features(df)\n",
    "\n",
    "# df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "\n",
    "# # Identify hash column\n",
    "# hash_col = \"hash_storeNbr_family_city_state_type_cluster\"\n",
    "\n",
    "# # Categorical columns detected automatically\n",
    "# cat_cols = [\"state\", \"store_nbr\", \"family\", \"city\", \"type\", \"cluster\", \"is_holiday\"]\n",
    "\n",
    "# # Convert to categorical codes (LightGBM-friendly)\n",
    "# for c in cat_cols:\n",
    "#     df[c] = df[c].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "# # Convert date to numeric\n",
    "# df[\"date_ordinal\"] = df[\"date\"].map(pd.Timestamp.toordinal)\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # Select features: all except target + hash column\n",
    "# # ---------------------------------------------------------\n",
    "# feature_cols = [c for c in df.columns if c not in [\"sales\", hash_col, \"date\"]]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"sales\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d2654b5-1393-4ab9-8078-2b1720c01995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56905141-e37b-427b-be28-81bee2c92732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Time-based validation split (last 28 days)\n",
    "# ---------------------------------------------------------\n",
    "cutoff = df[\"date\"].max() - pd.Timedelta(days=28)\n",
    "\n",
    "mask_train = df[\"date\"] <= cutoff\n",
    "mask_valid = df[\"date\"] > cutoff\n",
    "\n",
    "X_train = X[mask_train]\n",
    "y_train = y[mask_train]\n",
    "\n",
    "X_valid = X[mask_valid]\n",
    "y_valid = y[mask_valid]\n",
    "\n",
    "y_train_log = np.log1p(y_train) #y_train # \n",
    "y_valid_log = np.log1p(y_valid) #y_valid # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75ee719b-fd90-419c-81d2-4cdda72441aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Train LightGBM with MLflow\n",
    "# ---------------------------------------------------------\n",
    "mlflow.lightgbm.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm-pandas-training\"):\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 400,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 64,\n",
    "        \"min_child_samples\": 50,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 3,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train_log,\n",
    "        eval_set=[(X_train, y_train_log), (X_valid, y_valid_log)],\n",
    "        eval_metric=\"rmse\",\n",
    "        # verbose=False\n",
    "    )\n",
    "\n",
    "    # Validation prediction\n",
    "    val_pred = np.expm1(model.predict(X_valid)).clip(0, None)\n",
    "\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_valid, val_pred))\n",
    "    mlflow.log_metric(\"rmsle\", rmsle)\n",
    "\n",
    "    print(\"Validation RMSLE:\", rmsle)\n",
    "\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "print(\"Model saved to:\", model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d08c195-dec4-4356-9d95-077f083d7573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create dataframe for future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5088b3e2-d4a1-4322-81c7-fcfc9a8ce9df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find last known date\n",
    "last_date = spark.table(\"silver_training\") \\\n",
    "                 .selectExpr(\"max(date) as max_date\") \\\n",
    "                 .collect()[0][0]\n",
    "\n",
    "# Create future date range\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1),\n",
    "                             periods=90,  # change as needed\n",
    "                             freq=\"D\")\n",
    "\n",
    "# Build future frame using unique store / family combinations\n",
    "base = spark.table(\"silver_training\") \\\n",
    "    .select(\"state\", \"store_nbr\", \"family\", \"onpromotion\", \"city\", \"type\", \"cluster\", \"is_holiday\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .toPandas()\n",
    "\n",
    "\n",
    "# Cross join stores with future dates\n",
    "future_custom = base.assign(key=1).merge(\n",
    "    pd.DataFrame({\"date\": future_dates, \"key\": 1}),\n",
    "    on=\"key\"\n",
    ").drop(columns=\"key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4652a41-f0dc-4967-98a9-c3f2f917bd25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9076431b-065c-4a4d-9012-1257150896b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3129dbb-ef21-407d-92d2-dbcd14f777a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_custom_fe, feature_cols = make_features(future_custom)\n",
    "future_custom_fe[\"prediction\"] = np.expm1(\n",
    "    model.predict(future_custom_fe[feature_cols])\n",
    ").clip(0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f309eee8-7fe7-4a9b-8f3d-54c4432a6fce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_custom_fe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75d696f6-833c-47f1-b241-fc68fba5b9ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select max(date) from bronze_holidays_events;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33873ad0-9103-4702-94c8-2dea8aa588ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6558937498998189,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) MLFlow_sales_03 - working",
   "widgets": {}
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
