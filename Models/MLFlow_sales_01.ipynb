{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1914dd94-e745-49ac-97ef-483823ff08da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2025-12-11T00:59:25.321192Z",
     "iopub.status.busy": "2025-12-11T00:59:25.320900Z",
     "iopub.status.idle": "2025-12-11T01:06:44.097210Z",
     "shell.execute_reply": "2025-12-11T01:06:44.096011Z",
     "shell.execute_reply.started": "2025-12-11T00:59:25.321146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q mlflow lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "R = \"/kaggle/input/store-sales-time-series-forecasting\"\n",
    "ex = \"x_expt_01\"\n",
    "mdl = \"mdl_store_sales_demo\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///kaggle/working/mlruns\")\n",
    "mlflow.set_experiment(ex)\n",
    "\n",
    "tr = pd.read_csv(f\"{R}/train.csv\")\n",
    "ts = pd.read_csv(f\"{R}/test.csv\")\n",
    "o  = pd.read_csv(f\"{R}/oil.csv\")\n",
    "h  = pd.read_csv(f\"{R}/holidays_events.csv\")\n",
    "st = pd.read_csv(f\"{R}/stores.csv\")\n",
    "tn = pd.read_csv(f\"{R}/transactions.csv\")\n",
    "ss = pd.read_csv(f\"{R}/sample_submission.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for d in [tr,ts,o,h,tn]:\n",
    " d[\"date\"]=pd.to_datetime(d[\"date\"])\n",
    "\n",
    "tr[\"dow\"]=tr[\"date\"].dt.dayofweek\n",
    "ts[\"dow\"]=ts[\"date\"].dt.dayofweek\n",
    "tr[\"wek\"]=tr[\"dow\"].isin([5,6]).astype(int)\n",
    "ts[\"wek\"]=ts[\"dow\"].isin([5,6]).astype(int)\n",
    "\n",
    "fd = pd.date_range(tr[\"date\"].min(), ts[\"date\"].max(), freq=\"D\")\n",
    "o = o.set_index(\"date\").reindex(fd)\n",
    "o.index.name=\"date\"\n",
    "o[\"dcoilwtico\"]=o[\"dcoilwtico\"].ffill().bfill()\n",
    "o[\"dcoilwtico\"]=o[\"dcoilwtico\"].fillna(o[\"dcoilwtico\"].median())\n",
    "o=o.reset_index().rename(columns={\"dcoilwtico\":\"oil\"})\n",
    "\n",
    "h[\"hol\"]=(h[\"type\"]!=\"Work Day\").astype(int)\n",
    "h1=h.groupby(\"date\")[\"hol\"].max().reset_index()\n",
    "\n",
    "def f(d):\n",
    " return int(d.day in [15,30])\n",
    "\n",
    "tr[\"sal\"]=tr[\"date\"].map(f); ts[\"sal\"]=ts[\"date\"].map(f)\n",
    "e=pd.to_datetime(\"2016-04-16\")\n",
    "for z in [tr,ts]:\n",
    " z[\"eq\"] = ((z[\"date\"]>=e-pd.Timedelta(15,\"D\")) & (z[\"date\"]<=e+pd.Timedelta(15,\"D\"))).astype(int)\n",
    "\n",
    "tr=tr.merge(o,on=\"date\",how=\"left\")\n",
    "ts=ts.merge(o,on=\"date\",how=\"left\")\n",
    "tr=tr.merge(h1,on=\"date\",how=\"left\")\n",
    "ts=ts.merge(h1,on=\"date\",how=\"left\")\n",
    "tr[\"hol\"]=tr[\"hol\"].fillna(0).astype(int)\n",
    "ts[\"hol\"]=ts[\"hol\"].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for c in [\"city\",\"state\",\"type\",\"cluster\"]:\n",
    " st[c]=st[c].astype(str)\n",
    " m={v:i for i,v in enumerate(st[c].unique())}\n",
    " st[c]=st[c].map(m).astype(int)\n",
    "\n",
    "tr=tr.merge(st,on=\"store_nbr\",how=\"left\")\n",
    "ts=ts.merge(st,on=\"store_nbr\",how=\"left\")\n",
    "\n",
    "tr=tr.merge(tn,on=[\"store_nbr\",\"date\"],how=\"left\")\n",
    "ts=ts.merge(tn,on=[\"store_nbr\",\"date\"],how=\"left\")\n",
    "tr[\"transactions\"]=tr[\"transactions\"].fillna(0)\n",
    "ts[\"transactions\"]=ts[\"transactions\"].fillna(0)\n",
    "\n",
    "tr=tr.sort_values([\"store_nbr\",\"family\",\"date\"])\n",
    "tr[\"z\"]= (tr[\"sales\"]==0).astype(int)\n",
    "zz=[]; r=0; ps=None; pf=None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for _,w in tr[[\"store_nbr\",\"family\",\"z\"]].iterrows():\n",
    " if w[\"store_nbr\"]!=ps or w[\"family\"]!=pf:\n",
    "  r=0\n",
    " if w[\"z\"]==1: r+=1\n",
    " else: r=0\n",
    " zz.append(r)\n",
    " ps=w[\"store_nbr\"]; pf=w[\"family\"]\n",
    "\n",
    "tr[\"zr\"]=zz\n",
    "tr[\"sc\"]=(tr[\"zr\"]>=14).astype(int)\n",
    "ts[\"sc\"]=0\n",
    "\n",
    "tr[\"family\"]=tr[\"family\"].astype(str)\n",
    "ts[\"family\"]=ts[\"family\"].astype(str)\n",
    "fmap={v:i for i,v in enumerate(pd.concat([tr[\"family\"],ts[\"family\"]]).unique())}\n",
    "tr[\"fam\"]=tr[\"family\"].map(fmap)\n",
    "ts[\"fam\"]=ts[\"family\"].map(fmap)\n",
    "\n",
    "fc = [\"fam\",\"store_nbr\",\"city\",\"state\",\"type\",\"cluster\",\n",
    "      \"oil\",\"hol\",\"sal\",\"eq\",\"transactions\",\"sc\",\"dow\",\"wek\"]\n",
    "\n",
    "X=tr[fc]\n",
    "y=tr[\"sales\"].astype(float)\n",
    "Xt=ts[fc]\n",
    "\n",
    "cut = tr[\"date\"].max() - pd.Timedelta(28,\"D\")\n",
    "m1 = tr[\"date\"]<=cut\n",
    "m2 = tr[\"date\"]>cut\n",
    "Xtr = X[m1]\n",
    "ytr=y[m1]\n",
    "Xv  = X[m2]\n",
    "yv=y[m2]\n",
    "ytrlog=np.log1p(ytr)\n",
    "yvlog=np.log1p(yv)\n",
    "\n",
    "\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"r1\") as rr:\n",
    " p={\"n_estimators\":1000,\"learning_rate\":0.03,\"num_leaves\":64,\n",
    "    \"min_data_in_leaf\":50,\"feature_fraction\":0.8,\n",
    "    \"bagging_fraction\":0.8,\"bagging_freq\":3,\"random_state\":42}\n",
    " mdl1=lgb.LGBMRegressor(**p)\n",
    " mdl1.fit(Xtr,ytrlog,eval_set=[(Xtr,ytrlog),(Xv,yvlog)],eval_metric=\"rmse\")\n",
    " vp = mdl1.predict(Xv)\n",
    " vp = np.expm1(vp).clip(0,None)\n",
    " sc = np.sqrt(mean_squared_log_error(yv,vp))\n",
    " mlflow.log_metric(\"rmsle\",sc)\n",
    " print(\"rmsle\",sc)\n",
    " rid = rr.info.run_id\n",
    " muri=f\"runs:/{rid}/model\"\n",
    "\n",
    "rv=None\n",
    "try:\n",
    " x = mlflow.register_model(muri,mdl)\n",
    " rv=x.version\n",
    " print(\"reg\",rv)\n",
    "except:\n",
    " print(\"no registry\")\n",
    "\n",
    "if rv: loadu=f\"models:/{mdl}/{rv}\"\n",
    "else: loadu=muri\n",
    "\n",
    "m2load = mlflow.pyfunc.load_model(loadu)\n",
    "vp2 = m2load.predict(Xv)\n",
    "vp2 = np.expm1(vp2).clip(0,None)\n",
    "print(\"diff\",np.abs(vp - vp2).mean())\n",
    "\n",
    "vv = tr[m2].copy()\n",
    "vv[\"p\"]=vp\n",
    "d1 = vv.groupby(\"date\")[[\"sales\",\"p\"]].sum().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(d1[\"date\"],d1[\"sales\"])\n",
    "plt.plot(d1[\"date\"],d1[\"p\"])\n",
    "plt.title(\"daily\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "d1[\"r\"]=d1[\"sales\"]-d1[\"p\"]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(d1[\"date\"],d1[\"r\"])\n",
    "plt.axhline(0,color=\"black\")\n",
    "plt.title(\"res\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(d1[\"r\"],bins=50)\n",
    "plt.title(\"hist\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "vv[\"wk\"]=vv[\"date\"].dt.to_period(\"W\").dt.start_time\n",
    "d2=vv.groupby(\"wk\")[[\"sales\",\"p\"]].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(d2[\"wk\"],d2[\"sales\"])\n",
    "plt.plot(d2[\"wk\"],d2[\"p\"])\n",
    "plt.title(\"wk\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "top = vv.groupby(\"family\")[\"sales\"].sum().nlargest(6).index\n",
    "\n",
    "for fml in top:\n",
    " x=vv[vv[\"family\"]==fml].copy()\n",
    " x=x.groupby(\"date\")[[\"sales\",\"p\"]].sum().reset_index()\n",
    " plt.figure(figsize=(10,3))\n",
    " plt.plot(x[\"date\"],x[\"sales\"])\n",
    " plt.plot(x[\"date\"],x[\"p\"])\n",
    " plt.title(str(fml))\n",
    " plt.grid()\n",
    " plt.show()\n",
    "\n",
    "imp = pd.DataFrame({\"f\":fc,\"i\":mdl1.feature_importances_}).sort_values(\"i\")\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(imp[\"f\"],imp[\"i\"])\n",
    "plt.title(\"imp\")\n",
    "plt.grid(axis=\"x\")\n",
    "plt.show()\n",
    "\n",
    "tp = m2load.predict(Xt)\n",
    "tp = np.expm1(tp).clip(0,None)\n",
    "g = ts[[\"date\",\"store_nbr\",\"family\"]].copy()\n",
    "g[\"predicted_sales\"]=tp\n",
    "g.to_csv(\"gold_store_family_day_predictions.csv\",index=False)\n",
    "print(\"saved gold\")\n",
    "print(\"done\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MLFlow_sales_01",
   "widgets": {}
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
