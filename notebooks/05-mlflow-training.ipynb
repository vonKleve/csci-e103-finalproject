{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fe11333-1344-468b-a838-338ed5b3cfc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow Model Training Pipeline\n",
    "\n",
    "**Objective:** Train a LightGBM model to forecast store sales with MLflow experiment tracking\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load data from Silver layer\n",
    "2. Feature engineering\n",
    "3. Model training with validation\n",
    "4. Experiment tracking & model registration\n",
    "5. Performance visualization\n",
    "6. Generate predictions for Gold layer\n",
    "\n",
    "**Model:** LightGBM Regressor  \n",
    "**Target:** Sales forecasting (log-transformed)  \n",
    "**Metric:** RMSLE (Root Mean Squared Logarithmic Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c764c1-410a-484d-915b-c23813b41f0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q mlflow lightgbm\n",
    "%pip install synapseml\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a17a45de-3be6-46a5-84e1-ce0a4cb5ff30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ab81eb-f3dc-4338-85e4-8da833610273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MLflow Configuration\n",
    "# Get current username for experiment path\n",
    "current_user = spark.sql(\"SELECT current_user() as user\").collect()[0][\"user\"]\n",
    "EXPERIMENT_NAME = f\"/Users/{current_user}/store_sales_forecast\"\n",
    "MODEL_NAME = \"store_sales_lgbm\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(f\"MLflow experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Model name: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee3c26d-361e-4ae6-af35-b256606fac3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load Data from Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eabef6c-0795-4191-91c6-84afab03e726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load Silver tables\n",
    "spark.sql(\"USE cscie103_catalog.final_project\")\n",
    "\n",
    "print(\"Loading data from Silver layer...\")\n",
    "# train_df = spark.table(\"silver_train\")\n",
    "# oil_df = spark.table(\"silver_oil\")\n",
    "# holidays_df = spark.table(\"silver_holidays\")\n",
    "# stores_df = spark.table(\"silver_stores\")\n",
    "# transactions_df = spark.table(\"silver_transactions\")\n",
    "\n",
    "training_df = spark.table(\"silver_training\")\n",
    "test_df = spark.table(\"silver_test\")\n",
    "\n",
    "# print(f\"Train: {train_df.count():,} rows\")\n",
    "# print(f\"Oil: {oil_df.count():,} rows\")\n",
    "# print(f\"Holidays: {holidays_df.count():,} rows\")\n",
    "# print(f\"Stores: {stores_df.count():,} rows\")\n",
    "# print(f\"Transactions: {transactions_df.count():,} rows\")\n",
    "\n",
    "print(f\"Training: {training_df.count():,} rows\")\n",
    "print(f\"Test: {test_df.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df0ee9ca-5f6b-41ef-8978-2bf0d37f7ff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6da7f2b1-5152-42d3-ba8f-485e0d4c1eb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Convert date columns to datetime\n",
    "print(\"Converting date columns...\")\n",
    "for df in [train_df, test_df, oil_df, holidays_df, transactions_df]:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "print(\"Date conversion complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc578e58-85c4-45fc-88fb-9e7c3d7c96c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Temporal features: day of week and weekend indicator\n",
    "print(\"Creating temporal features...\")\n",
    "\n",
    "train_df[\"day_of_week\"] = train_df[\"date\"].dt.dayofweek\n",
    "test_df[\"day_of_week\"] = test_df[\"date\"].dt.dayofweek\n",
    "\n",
    "train_df[\"is_weekend\"] = train_df[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "test_df[\"is_weekend\"] = test_df[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "\n",
    "print(\"✓ Temporal features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b84b18-30c6-4a87-9d12-c01c0b12cbc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Oil price features: forward/backward fill missing values\n",
    "print(\"Processing oil prices...\")\n",
    "\n",
    "# Create complete date range\n",
    "full_date_range = pd.date_range(train_df[\"date\"].min(), test_df[\"date\"].max(), freq=\"D\")\n",
    "\n",
    "# Reindex oil data to fill gaps\n",
    "oil_df = oil_df.set_index(\"date\").reindex(full_date_range)\n",
    "oil_df.index.name = \"date\"\n",
    "\n",
    "# Fill missing values (forward fill, then backward fill, then median)\n",
    "oil_df[\"dcoilwtico\"] = oil_df[\"dcoilwtico\"].ffill().bfill()\n",
    "oil_df[\"dcoilwtico\"] = oil_df[\"dcoilwtico\"].fillna(oil_df[\"dcoilwtico\"].median())\n",
    "\n",
    "# Rename column for clarity\n",
    "oil_df = oil_df.reset_index().rename(columns={\"dcoilwtico\": \"oil_price\"})\n",
    "\n",
    "print(f\"✓ Oil prices processed, missing values filled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a293fc70-67d5-4fb7-8990-7b6f72ab7ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "#  Holiday features\n",
    "print(\"Creating holiday features...\")\n",
    "\n",
    "# Create binary holiday indicator (1 if not a work day)\n",
    "holidays_df[\"is_holiday\"] = (holidays_df[\"type\"] != \"Work Day\").astype(int)\n",
    "\n",
    "# Aggregate by date (max in case of multiple holidays per day)\n",
    "holidays_agg = holidays_df.groupby(\"date\")[\"is_holiday\"].max().reset_index()\n",
    "\n",
    "print(f\"✓ Holiday features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d787187-3385-40af-b861-6802d1aaa40f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Salary day feature (15th and 30th of month)\n",
    "print(\"Creating salary day indicator...\")\n",
    "\n",
    "def is_salary_day(date):\n",
    "    \"\"\"Returns 1 if date is 15th or 30th (typical salary days in Ecuador)\"\"\"\n",
    "    return int(date.day in [15, 30])\n",
    "\n",
    "train_df[\"is_salary_day\"] = train_df[\"date\"].map(is_salary_day)\n",
    "test_df[\"is_salary_day\"] = test_df[\"date\"].map(is_salary_day)\n",
    "\n",
    "print(\"✓ Salary day indicator created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "868f027e-873e-4ec9-9774-21e91a0d1bb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# ----------------------------------------- TODO: LOOK INTO\n",
    "# Earthquake impact feature (April 16, 2016 earthquake in Ecuador)\n",
    "print(\"Creating earthquake impact feature...\")\n",
    "\n",
    "EARTHQUAKE_DATE = pd.to_datetime(\"2016-04-16\")\n",
    "EARTHQUAKE_WINDOW_DAYS = 15\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df[\"earthquake_impact\"] = (\n",
    "        (df[\"date\"] >= EARTHQUAKE_DATE - pd.Timedelta(EARTHQUAKE_WINDOW_DAYS, \"D\")) & \n",
    "        (df[\"date\"] <= EARTHQUAKE_DATE + pd.Timedelta(EARTHQUAKE_WINDOW_DAYS, \"D\"))\n",
    "    ).astype(int)\n",
    "\n",
    "print(f\"✓ Earthquake impact window: ±{EARTHQUAKE_WINDOW_DAYS} days from {EARTHQUAKE_DATE.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "792a7012-226d-4d95-94b2-95161f778e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Merge external features\n",
    "print(\"Merging external features...\")\n",
    "\n",
    "train_df = train_df.merge(oil_df, on=\"date\", how=\"left\")\n",
    "test_df = test_df.merge(oil_df, on=\"date\", how=\"left\")\n",
    "\n",
    "train_df = train_df.merge(holidays_agg, on=\"date\", how=\"left\")\n",
    "test_df = test_df.merge(holidays_agg, on=\"date\", how=\"left\")\n",
    "\n",
    "# Fill missing holidays with 0\n",
    "train_df[\"is_holiday\"] = train_df[\"is_holiday\"].fillna(0).astype(int)\n",
    "test_df[\"is_holiday\"] = test_df[\"is_holiday\"].fillna(0).astype(int)\n",
    "\n",
    "print(\"✓ External features merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8eddf77-33c2-4888-81f1-2adb1d681e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Store features: encode categorical variables\n",
    "print(\"Encoding store features...\")\n",
    "\n",
    "categorical_cols = [\"city\", \"state\", \"type\", \"cluster\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    stores_df[col] = stores_df[col].astype(str)\n",
    "    # Create mapping\n",
    "    unique_values = stores_df[col].unique()\n",
    "    encoding_map = {value: idx for idx, value in enumerate(unique_values)}\n",
    "    stores_df[col] = stores_df[col].map(encoding_map).astype(int)\n",
    "    print(f\"  • {col}: {len(unique_values)} unique values encoded\")\n",
    "\n",
    "# Merge store features\n",
    "train_df = train_df.merge(stores_df, on=\"store_nbr\", how=\"left\")\n",
    "test_df = test_df.merge(stores_df, on=\"store_nbr\", how=\"left\")\n",
    "\n",
    "print(\"✓ Store features encoded and merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa15f2be-b9d4-4e36-acfa-8a3b54fc04f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Transaction features\n",
    "print(\"Merging transaction data...\")\n",
    "\n",
    "train_df = train_df.merge(transactions_df, on=[\"store_nbr\", \"date\"], how=\"left\")\n",
    "test_df = test_df.merge(transactions_df, on=[\"store_nbr\", \"date\"], how=\"left\")\n",
    "\n",
    "# Fill missing transactions with 0\n",
    "train_df[\"transactions\"] = train_df[\"transactions\"].fillna(0)\n",
    "test_df[\"transactions\"] = test_df[\"transactions\"].fillna(0)\n",
    "\n",
    "print(\"✓ Transaction data merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "759fa010-7ac6-4838-8c5e-962d9b30aee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# ----------------------------------------- TODO: LOOK INTO\n",
    "# Zero sales streak feature\n",
    "print(\"Calculating zero sales streak...\")\n",
    "\n",
    "train_df = train_df.sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "train_df[\"is_zero_sales\"] = (train_df[\"sales\"] == 0).astype(int)\n",
    "\n",
    "# Calculate consecutive zero sales days\n",
    "zero_streaks = []\n",
    "streak_count = 0\n",
    "prev_store = None\n",
    "prev_family = None\n",
    "\n",
    "for _, row in train_df[[\"store_nbr\", \"family\", \"is_zero_sales\"]].iterrows():\n",
    "    # Reset streak if store/family changes\n",
    "    if row[\"store_nbr\"] != prev_store or row[\"family\"] != prev_family:\n",
    "        streak_count = 0\n",
    "    \n",
    "    # Update streak\n",
    "    if row[\"is_zero_sales\"] == 1:\n",
    "        streak_count += 1\n",
    "    else:\n",
    "        streak_count = 0\n",
    "    \n",
    "    zero_streaks.append(streak_count)\n",
    "    prev_store = row[\"store_nbr\"]\n",
    "    prev_family = row[\"family\"]\n",
    "\n",
    "train_df[\"zero_sales_streak\"] = zero_streaks\n",
    "\n",
    "# Store closed indicator (14+ days of zero sales)\n",
    "train_df[\"store_closed\"] = (train_df[\"zero_sales_streak\"] >= 14).astype(int)\n",
    "test_df[\"store_closed\"] = 0  # Assume stores open for test period\n",
    "\n",
    "print(f\"✓ Zero sales streaks calculated\")\n",
    "print(f\"  • Max streak: {train_df['zero_sales_streak'].max()} days\")\n",
    "print(f\"  • Closed store instances: {train_df['store_closed'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7ebdc01-312d-405f-b8b6-9dc1e45f460c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Family (product category) encoding\n",
    "print(\"Encoding product families...\")\n",
    "\n",
    "train_df[\"family\"] = train_df[\"family\"].astype(str)\n",
    "test_df[\"family\"] = test_df[\"family\"].astype(str)\n",
    "\n",
    "# Create unified encoding for train and test\n",
    "all_families = pd.concat([train_df[\"family\"], test_df[\"family\"]]).unique()\n",
    "family_encoding = {family: idx for idx, family in enumerate(all_families)}\n",
    "\n",
    "train_df[\"family_encoded\"] = train_df[\"family\"].map(family_encoding)\n",
    "test_df[\"family_encoded\"] = test_df[\"family\"].map(family_encoding)\n",
    "\n",
    "print(f\"✓ {len(all_families)} product families encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15682810-19ad-4d21-94d2-61289b175ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "410afb2d-5382-44c6-8249-2698d424a35b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from datetime import timedelta, date\n",
    "\n",
    "# --- Configuration ---\n",
    "VALIDATION_DAYS = 28\n",
    "TARGET_COL = \"sales\"\n",
    "FEATURE_COLS = [\n",
    "    'strIndxer_family', 'store_nbr', 'strIndxer_city', 'strIndxer_state',\n",
    "    'strIndxer_type', 'cluster', 'is_holiday', 'is_salary_day',\n",
    "    'transactions', 'day_of_week'\n",
    "]\n",
    "# Ensure the 'date' and TARGET_COL columns are also available for splitting/transforming\n",
    "ALL_COLS_FOR_SPLIT = FEATURE_COLS + [TARGET_COL, \"date\"]\n",
    "\n",
    "# 1. Select the relevant features and target from the full training dataset\n",
    "# Note: We select all needed columns, including 'date' and 'sales'\n",
    "training_df = training_df.select(ALL_COLS_FOR_SPLIT)\n",
    "test_df = test_df.select(FEATURE_COLS) # Keep test_df as features only\n",
    "\n",
    "print(f\"Features prepared\")\n",
    "print(f\"Full Training set samples: {training_df.count():,}\")\n",
    "print(f\"Test samples: {test_df.count():,}\")\n",
    "\n",
    "# --- Train/Validation Split Logic ---\n",
    "\n",
    "# 1. Find the maximum date in the 'date' column (PySpark Action)\n",
    "max_date_py = training_df.agg(F.max(\"date\")).collect()[0][0]\n",
    "\n",
    "# 2. Calculate the validation cutoff date (Python calculation)\n",
    "# We subtract the days from the resulting Python date object\n",
    "if isinstance(max_date_py, date):\n",
    "    validation_cutoff_date = max_date_py - timedelta(days=VALIDATION_DAYS)\n",
    "else:\n",
    "    # Handle case where it might be a string or different type, though unlikely if schema is correct\n",
    "    print(\"Warning: Max date calculation type mismatch.\")\n",
    "    validation_cutoff_date = F.to_date(F.lit(max_date_py)) - F.expr(f\"INTERVAL {VALIDATION_DAYS} DAYS\")\n",
    "\n",
    "\n",
    "print(f\"The calculated validation cutoff date is: {validation_cutoff_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# 3. Create the Training and Validation DataFrames by filtering the main DataFrame\n",
    "train_df = training_df.filter(F.col(\"date\") <= validation_cutoff_date)\n",
    "val_df = training_df.filter(F.col(\"date\") > validation_cutoff_date)\n",
    "\n",
    "# 4. Log Transform Target (Sales)\n",
    "# Create the log-transformed target column (e.g., 'sales_log')\n",
    "train_df = train_df.withColumn(\n",
    "    f\"{TARGET_COL}_log\",\n",
    "    F.log1p(F.col(TARGET_COL)).cast(DoubleType()) # Cast to DoubleType for consistency\n",
    ")\n",
    "val_df = val_df.withColumn(\n",
    "    f\"{TARGET_COL}_log\",\n",
    "    F.log1p(F.col(TARGET_COL)).cast(DoubleType()) # Cast to DoubleType\n",
    ")\n",
    "\n",
    "# 5. Final Selection of X and y (PySpark DataFrames)\n",
    "# We select the features (X) and the new log-transformed target (y_log)\n",
    "X_train = train_df.select(FEATURE_COLS)\n",
    "y_train_log = train_df.select(f\"{TARGET_COL}_log\")\n",
    "\n",
    "X_val = val_df.select(FEATURE_COLS)\n",
    "y_val_log = val_df.select(f\"{TARGET_COL}_log\")\n",
    "\n",
    "# 6. Print Summary Counts (Use counts from the filtered DFs)\n",
    "train_count = train_df.count()\n",
    "val_count = val_df.count()\n",
    "\n",
    "print(\"\\nTrain/validation split:\")\n",
    "print(f\"  • Training: {train_count:,} samples (up to {validation_cutoff_date.strftime('%Y-%m-%d')})\")\n",
    "print(f\"  • Validation: {val_count:,} samples (last {VALIDATION_DAYS} days)\")\n",
    "print(f\"  • Log transformation applied to target variable: '{TARGET_COL}_log'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f57e144e-81cd-4570-96fb-bafde0d2f9c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Model Training with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c86ef31-dbb1-4d75-ab4a-6fb4bbfdcb76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Import the Spark LightGBM classes\n",
    "from synapse.ml.lightgbm import LightGBMRegressor # Or lightgbm.spark.LightGBMRegressor\n",
    "\n",
    "# --- Configuration (from previous steps) ---\n",
    "TARGET_COL_LOG = \"sales_log\"\n",
    "TARGET_COL = \"sales\" # Original target column name for final metric calculation\n",
    "FEATURE_COLS = [\n",
    "    'strIndxer_family', 'store_nbr', 'strIndxer_city', 'strIndxer_state',\n",
    "    'strIndxer_type', 'cluster', 'is_holiday', 'is_salary_day',\n",
    "    'transactions', 'day_of_week'\n",
    "]\n",
    "# Assume 'train_df' and 'val_df' are your PySpark DataFrames from the last step\n",
    "\n",
    "# 1. Feature Vector Assembly (MANDATORY PySpark ML step)\n",
    "# PySpark ML models require all features to be in a single vector column.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=FEATURE_COLS,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "train_df_assembled = assembler.transform(train_df)\n",
    "val_df_assembled = assembler.transform(val_df)\n",
    "# The assembled DataFrames now have a new 'features' column\n",
    "\n",
    "mlflow.lightgbm.autolog() # This should still work if you use a recent LightGBM library\n",
    "\n",
    "print(\"Starting model training with MLflow tracking...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_spark_baseline\") as run:\n",
    "    # 2. Model Hyperparameters (Adapted for Spark-LightGBM)\n",
    "    # Note the change in parameter names from Python-LGBM to Spark-LGBM\n",
    "    params = {\n",
    "        \"numIterations\": 1000,\n",
    "        \"learningRate\": 0.03,\n",
    "        \"numLeaves\": 64,\n",
    "        \"minDataInLeaf\": 50,\n",
    "        \"featureFraction\": 0.8,\n",
    "        \"baggingFraction\": 0.8,\n",
    "        \"baggingFreq\": 3,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    print(\"Hyperparameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "    # 3. Initialize and Train Model\n",
    "    # Specify feature column, label column, and set parameters\n",
    "    lgbm = (\n",
    "        LightGBMRegressor(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=TARGET_COL_LOG, # Train on the log-transformed target\n",
    "            **params\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Training the model (Spark-LightGBM handles evaluation internally)\n",
    "    model = lgbm.fit(train_df_assembled)\n",
    "\n",
    "    # 4. Generate Predictions on Validation Set\n",
    "    val_pred_df = model.transform(val_df_assembled)\n",
    "\n",
    "    # 5. Inverse Log Transform and Clip Predictions (PySpark SQL Functions)\n",
    "    # Equivalent to: np.expm1(val_pred_log).clip(0, None)\n",
    "    val_pred_df = val_pred_df.withColumn(\n",
    "        \"prediction_clipped\",\n",
    "        F.greatest(F.lit(0.0), F.expm1(F.col(\"prediction\"))) # Use F.greatest for clip(0, None)\n",
    "    )\n",
    "\n",
    "    # 6. Calculate RMSLE (Root Mean Squared Logarithmic Error)\n",
    "    # RMSLE is NOT a native PySpark ML metric, but we can use the formula:\n",
    "    # RMSE of (log(1+actual) - log(1+predicted))\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=TARGET_COL, # Use the original 'sales' column as the true label\n",
    "        predictionCol=\"prediction_clipped\",\n",
    "        metricName=\"rmsle\"\n",
    "    )\n",
    "    # Note: Spark's built-in evaluator needs the data transformed to match RMSLE definition\n",
    "    \n",
    "    # Custom RMSLE calculation (more accurate for competition metric):\n",
    "    rmsle_expr = F.sqrt(F.mean(F.pow(F.log1p(F.col(TARGET_COL)) - F.log1p(F.col(\"prediction_clipped\")), 2)))\n",
    "    \n",
    "    rmsle = val_pred_df.select(rmsle_expr).collect()[0][0]\n",
    "    mlflow.log_metric(\"rmsle\", rmsle)\n",
    "\n",
    "    print(f\"\\n✓ Model trained successfully\")\n",
    "    print(f\"  • RMSLE: {rmsle:.4f}\")\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    print(f\"  • Run ID: {run_id}\")\n",
    "\n",
    "    # Log the Spark-LightGBM Model to MLflow\n",
    "    # Note: The Spark-LightGBM model is a Spark PipelineModel, log it directly.\n",
    "    # mlflow.spark.log_model(model, \"lightgbm-spark-model\")\n",
    "    # For autologging, this step might be automatic, but this is the manual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b82760c3-323e-4e6f-bd8b-f117dd13815f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Enable MLflow autologging for LightGBM\n",
    "mlflow.lightgbm.autolog()\n",
    "\n",
    "print(\"Starting model training with MLflow tracking...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_baseline\") as run:\n",
    "    # Model hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"num_leaves\": 64,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 3,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    print(\"Hyperparameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train_log,\n",
    "        eval_set=[(X_train, y_train_log), (X_val, y_val_log)],\n",
    "        eval_metric=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    # Generate predictions\n",
    "    val_pred_log = model.predict(X_val)\n",
    "    val_pred = np.expm1(val_pred_log).clip(0, None)  # Inverse log transform\n",
    "    \n",
    "    # Calculate RMSLE (competition metric)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_val, val_pred))\n",
    "    mlflow.log_metric(\"rmsle\", rmsle)\n",
    "    \n",
    "    print(f\"\\n✓ Model trained successfully\")\n",
    "    print(f\"  • RMSLE: {rmsle:.4f}\")\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    print(f\"  • Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25cc13c-b4fc-4210-8f9d-8521cc034994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2a7436-93f5-41dc-a349-4a5a9b2a6300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Register model in MLflow Model Registry\n",
    "print(\"Registering model...\")\n",
    "\n",
    "model_version = None\n",
    "try:\n",
    "    registered_model = mlflow.register_model(model_uri, MODEL_NAME)\n",
    "    model_version = registered_model.version\n",
    "    print(f\"✓ Model registered: {MODEL_NAME} v{model_version}\")\n",
    "    load_uri = f\"models:/{MODEL_NAME}/{model_version}\"\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Model registry not available: {e}\")\n",
    "    print(\"  Using run URI instead\")\n",
    "    load_uri = model_uri\n",
    "\n",
    "# Load and verify registered model\n",
    "loaded_model = mlflow.pyfunc.load_model(load_uri)\n",
    "val_pred_reloaded = loaded_model.predict(X_val)\n",
    "val_pred_reloaded = np.expm1(val_pred_reloaded).clip(0, None)\n",
    "\n",
    "prediction_diff = np.abs(val_pred - val_pred_reloaded).mean()\n",
    "print(f\"✓ Model loaded and verified\")\n",
    "print(f\"  • Average prediction difference: {prediction_diff:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2a8229-7d52-4ced-8f56-5130fa82954b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Model Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d427b114-b36c-4fe1-af95-1040d3addf03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Prepare validation results\n",
    "val_results = train_df[val_mask].copy()\n",
    "val_results[\"predicted_sales\"] = val_pred\n",
    "\n",
    "# Daily aggregated results\n",
    "daily_results = val_results.groupby(\"date\")[[\"sales\", \"predicted_sales\"]].sum().reset_index()\n",
    "\n",
    "print(f\"✓ Validation period: {daily_results['date'].min().date()} to {daily_results['date'].max().date()}\")\n",
    "print(f\"  • Total actual sales: ${daily_results['sales'].sum():,.0f}\")\n",
    "print(f\"  • Total predicted sales: ${daily_results['predicted_sales'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ea33afb-5669-45f8-887a-a21a3754d16a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Visualization 1: Daily actual vs predicted\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(daily_results[\"date\"], daily_results[\"sales\"], label=\"Actual Sales\", linewidth=2)\n",
    "plt.plot(daily_results[\"date\"], daily_results[\"predicted_sales\"], label=\"Predicted Sales\", linewidth=2, alpha=0.8)\n",
    "plt.title(\"Daily Sales: Actual vs Predicted (Validation Period)\", fontsize=14)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Sales ($)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f00fbcb0-0253-48ee-8ea5-fb80580282fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Visualization 2: Prediction residuals\n",
    "daily_results[\"residual\"] = daily_results[\"sales\"] - daily_results[\"predicted_sales\"]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(daily_results[\"date\"], daily_results[\"residual\"], linewidth=2, color=\"orange\")\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "plt.title(\"Prediction Residuals (Actual - Predicted)\", fontsize=14)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual ($)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual statistics:\")\n",
    "print(f\"  • Mean: ${daily_results['residual'].mean():,.2f}\")\n",
    "print(f\"  • Std: ${daily_results['residual'].std():,.2f}\")\n",
    "print(f\"  • Min: ${daily_results['residual'].min():,.2f}\")\n",
    "print(f\"  • Max: ${daily_results['residual'].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e416ff6e-c89a-472d-a843-bff2d0e2060c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Visualization 3: Residual distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(daily_results[\"residual\"], bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Zero Error\")\n",
    "plt.title(\"Distribution of Prediction Residuals\", fontsize=14)\n",
    "plt.xlabel(\"Residual ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd80189-c373-43dd-a736-03cdd43505fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Visualization 4: Weekly aggregation\n",
    "val_results[\"week\"] = val_results[\"date\"].dt.to_period(\"W\").dt.start_time\n",
    "weekly_results = val_results.groupby(\"week\")[[\"sales\", \"predicted_sales\"]].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(weekly_results[\"week\"], weekly_results[\"sales\"], marker=\"o\", label=\"Actual\", linewidth=2)\n",
    "plt.plot(weekly_results[\"week\"], weekly_results[\"predicted_sales\"], marker=\"s\", label=\"Predicted\", linewidth=2)\n",
    "plt.title(\"Weekly Sales: Actual vs Predicted\", fontsize=14)\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Total Sales ($)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f175f86-76b1-4962-8bd7-e8fe61acbc7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Visualization 5: Performance by top product families\n",
    "top_families = val_results.groupby(\"family\")[\"sales\"].sum().nlargest(6).index\n",
    "\n",
    "print(f\"Top {len(top_families)} product families by sales:\")\n",
    "for i, family in enumerate(top_families, 1):\n",
    "    family_sales = val_results[val_results[\"family\"] == family][\"sales\"].sum()\n",
    "    print(f\"  {i}. {family}: ${family_sales:,.0f}\")\n",
    "\n",
    "for family in top_families:\n",
    "    family_data = val_results[val_results[\"family\"] == family].copy()\n",
    "    family_daily = family_data.groupby(\"date\")[[\"sales\", \"predicted_sales\"]].sum().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.plot(family_daily[\"date\"], family_daily[\"sales\"], label=\"Actual\", linewidth=2)\n",
    "    plt.plot(family_daily[\"date\"], family_daily[\"predicted_sales\"], label=\"Predicted\", linewidth=2, alpha=0.8)\n",
    "    plt.title(f\"Product Family: {family}\", fontsize=12)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Sales ($)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "771d9b3e-a971-4b16-ad84-81c758464c92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Visualization 6: Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": FEATURE_COLS,\n",
    "    \"importance\": model.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance[\"feature\"], feature_importance[\"importance\"])\n",
    "plt.title(\"Feature Importance\", fontsize=14)\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.grid(axis=\"x\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "for i, row in feature_importance.tail(5)[::-1].iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6e587ac-ec59-46f2-b4f3-52eaa9fa3fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd5fa9f0-d024-4b95-bf5d-f625bdf28dd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Generate predictions for test set\n",
    "print(\"Generating test set predictions...\")\n",
    "\n",
    "test_pred_log = loaded_model.predict(X_test)\n",
    "test_pred = np.expm1(test_pred_log).clip(0, None)\n",
    "\n",
    "# Prepare predictions dataframe\n",
    "predictions_df = test_df[[\"date\", \"store_nbr\", \"family\"]].copy()\n",
    "predictions_df[\"predicted_sales\"] = test_pred\n",
    "\n",
    "print(f\"✓ Test predictions generated\")\n",
    "print(f\"  • Total predictions: {len(predictions_df):,}\")\n",
    "print(f\"  • Date range: {predictions_df['date'].min().date()} to {predictions_df['date'].max().date()}\")\n",
    "print(f\"  • Predicted total sales: ${test_pred.sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d04297-9896-48de-84e0-3d7c77c69e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Save predictions to Gold layer\n",
    "print(\"Saving predictions to Gold layer...\")\n",
    "\n",
    "predictions_spark = spark.createDataFrame(predictions_df)\n",
    "predictions_spark.write.mode(\"overwrite\").saveAsTable(\"cscie103_catalog.final_project.gold_predictions\")\n",
    "\n",
    "print(\"✓ Predictions saved to gold_predictions table\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING PIPELINE COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ Model: {MODEL_NAME}\")\n",
    "print(f\"✓ RMSLE: {rmsle:.4f}\")\n",
    "print(f\"✓ Predictions: gold_predictions table\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05-mlflow-training",
   "widgets": {}
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
