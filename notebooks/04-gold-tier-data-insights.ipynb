{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b10f7f4-22cf-471e-8c94-83c8ff269595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Building Out Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3260d1e8-189e-4be5-a62f-a72a0f64fbc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "VOLUME_ROOT_PATH = \"/Volumes/cscie103_catalog/final_project\"\n",
    "VOLUME_DATA_DIR = f\"{VOLUME_ROOT_PATH}/data\"\n",
    "\n",
    "CATALOG_NAME = \"cscie103_catalog\"\n",
    "SCHEMA_NAME = \"final_project\"\n",
    "spark.sql(f\"USE {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "\n",
    "class DataframeNames:\n",
    "    HOLIDAYS = \"holidays\"\n",
    "    OIL = \"oil\"\n",
    "    STORES = \"stores\"\n",
    "    TEST = \"test\"\n",
    "    TRAIN = \"train\"\n",
    "    TRANSACTIONS = \"transactions\"\n",
    "    TRAINING = \"training\"\n",
    "\n",
    "    ALL = [ HOLIDAYS, OIL, STORES, TEST, TRAIN, TRANSACTIONS, TRAINING ]\n",
    "\n",
    "class DataTier:\n",
    "    BRONZE = \"bronze\"\n",
    "    SILVER = \"silver\"\n",
    "    GOLD = \"gold\"\n",
    "\n",
    "    def getBronzeName(tablename):\n",
    "        return DataTier.BRONZE + \"_\" + tablename\n",
    "\n",
    "    def getSilverName(tablename):\n",
    "        return DataTier.SILVER + \"_\" + tablename\n",
    "    \n",
    "    def getGoldName(tablename):\n",
    "        return DataTier.GOLD + \"_\" + tablename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68aa9faf-60a5-4ef9-b94a-afaf7da15cad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook: 04_gold_daily_fact_notebook\n",
    "# Default language: Python\n",
    "\n",
    "# =========================================\n",
    "# 1. Setup\n",
    "# =========================================\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "catalog = \"cscie103_catalog\"\n",
    "schema  = \"final_project\"\n",
    "\n",
    "spark.sql(f\"USE {catalog}.{schema}\")\n",
    "\n",
    "# =========================================\n",
    "# 2. Load Silver tables\n",
    "# =========================================\n",
    "silver_train  = spark.table(\"silver_train\")            # date, store_nbr, family, sales, onpromotion, ...\n",
    "silver_stores = spark.table(\"silver_stores\")           # store_nbr, city, state, cluster, type, ...\n",
    "silver_oil    = spark.table(\"silver_oil\")              # date, dcoilwtico\n",
    "silver_hol    = spark.table(\"silver_holidays\")         # date, is_holiday, ...\n",
    "silver_tx     = spark.table(\"silver_transactions\")     # date, store_nbr, transactions\n",
    "\n",
    "# =========================================\n",
    "# 3. Build base_fact at dateâ€“storeâ€“family grain\n",
    "# =========================================\n",
    "\n",
    "# Normalize is_holiday safely to 0/1 int\n",
    "h_str = F.col(\"h.is_holiday\").cast(\"string\")\n",
    "is_holiday_expr = (\n",
    "    F.when(h_str.isin(\"True\", \"true\", \"1\"), F.lit(1))\n",
    "     .when(h_str.isin(\"False\", \"false\", \"0\"), F.lit(0))\n",
    "     .otherwise(F.lit(0))\n",
    "     .cast(\"int\")\n",
    "     .alias(\"is_holiday\")\n",
    ")\n",
    "\n",
    "base_fact = (\n",
    "    silver_train.alias(\"t\")\n",
    "    # Add store attributes (city/state/cluster)\n",
    "    .join(silver_stores.alias(\"s\"), \"store_nbr\", \"left\")\n",
    "    # Daily store-level transactions\n",
    "    .join(silver_tx.alias(\"x\"), [\"date\", \"store_nbr\"], \"left\")\n",
    "    # Oil price by date\n",
    "    .join(silver_oil.alias(\"o\"), \"date\", \"left\")\n",
    "    # Holidays by date\n",
    "    .join(silver_hol.alias(\"h\"), \"date\", \"left\")\n",
    "    .select(\n",
    "        F.col(\"t.id\").alias(\"id\"),\n",
    "        F.col(\"t.date\").alias(\"date\"),\n",
    "        F.col(\"t.store_nbr\").alias(\"store_nbr\"),\n",
    "        F.col(\"t.family\").alias(\"family\"),\n",
    "        F.col(\"t.sales\").cast(\"double\").alias(\"sales\"),\n",
    "        F.col(\"t.onpromotion\").cast(\"int\").alias(\"onpromotion\"),\n",
    "        F.col(\"x.transactions\").cast(\"int\").alias(\"transactions\"),\n",
    "        F.col(\"o.dcoilwtico\").cast(\"double\").alias(\"dcoilwtico\"),\n",
    "        F.col(\"s.city\").alias(\"city\"),\n",
    "        F.col(\"s.state\").alias(\"state\"),\n",
    "        F.col(\"s.type\").alias(\"store_type\"),\n",
    "        F.col(\"s.cluster\").alias(\"cluster\"),\n",
    "        is_holiday_expr\n",
    "    ).dropDuplicates([\"id\", \"date\", \"store_nbr\", \"family\"]) \n",
    ")\n",
    "\n",
    "# =========================================\n",
    "# 3b. Add core time features\n",
    "# =========================================\n",
    "base_fact = (\n",
    "    base_fact\n",
    "    .withColumn(\"year\", F.year(\"date\"))\n",
    "    .withColumn(\"month\", F.month(\"date\"))\n",
    "    .withColumn(\"day\", F.dayofmonth(\"date\"))\n",
    "    .withColumn(\"week_of_year\", F.weekofyear(\"date\"))\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\"))              # 1=Sun, 7=Sat\n",
    "    .withColumn(\"is_weekend\", F.col(\"day_of_week\").isin(1, 7).cast(\"int\"))\n",
    ")\n",
    "\n",
    "display(base_fact.limit(20))\n",
    "print(\"Rows in base_fact:\", base_fact.count())\n",
    "\n",
    "# =========================================\n",
    "# 4. Save as Gold table: gold_daily_store_family\n",
    "# =========================================\n",
    "\n",
    "# Drop if exists to avoid schema merge issues during development\n",
    "spark.sql(\"DROP TABLE IF EXISTS gold_daily_store_family\")\n",
    "\n",
    "(\n",
    "    base_fact\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"gold_daily_store_family\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Created gold_daily_store_family (with time features)\")\n",
    "# ================================================\n",
    "# 5. Demonstrate MERGE INTO for Gold upserts\n",
    "# ================================================\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable   # <-- REQUIRED IMPORT\n",
    "\n",
    "# Select 5 representative rows and apply realistic changes\n",
    "updates = (\n",
    "    base_fact\n",
    "        .orderBy(\"date\", \"store_nbr\", \"family\")\n",
    "        .limit(5)\n",
    "        # Simulate new sales corrections\n",
    "        .withColumn(\"sales\", F.col(\"sales\") + 25)\n",
    "        # Mark these as being newly put on promotion\n",
    "        .withColumn(\"onpromotion\", F.lit(1))\n",
    ")\n",
    "\n",
    "display(updates)\n",
    "\n",
    "# Load Delta table for merge\n",
    "# THIS SECTION DOES NOT WORK FOR NOW\n",
    "# delta_gold = DeltaTable.forName(spark, \"gold_daily_store_family\")\n",
    "\n",
    "# (\n",
    "#     delta_gold.alias(\"g\")\n",
    "#     .merge(\n",
    "#         source=updates.alias(\"u\"),\n",
    "#         condition=(\n",
    "#             \"g.date = u.date AND \"\n",
    "#             \"g.store_nbr = u.store_nbr AND \"\n",
    "#             \"g.family = u.family\"\n",
    "#         ),\n",
    "#     )\n",
    "#     .whenMatchedUpdateAll()\n",
    "#     .whenNotMatchedInsertAll()\n",
    "#     .execute()\n",
    "# )\n",
    "\n",
    "print(\"ðŸ”„ Upsert (MERGE INTO) demonstration completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c80c611-b309-40b0-afaa-b77cf06e5294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"cscie103_catalog.final_project.gold_daily_store_family\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6843e54-7003-4ba6-9bbc-f2f605dd5b21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM cscie103_catalog.final_project.gold_daily_store_family\n",
    "WHERE sales = 1\n",
    "  AND is_holiday IS NOT NULL LIMIT 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2423ea-8024-4a23-b85a-5c69703813f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- just to validate this numbers should be 965693.65\n",
    "SELECT SUM(SALES) FROM cscie103_catalog.final_project.gold_daily_store_family WHERE date='2017-08-05'"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8349099331492908,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04-gold-tier-data-insights",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
